{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import time\n",
    "\n",
    "\n",
    "# In[432]:\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "\n",
    "# ### Load Data\n",
    "\n",
    "# In[473]:\n",
    "\n",
    "\n",
    "col_file = open('/home/jjohn273/git/ECBDL14-Classification/data/columns.csv', 'r')\n",
    "columns = col_file.read().strip().split(',')\n",
    "columns = [col if col != 'class' else 'target' for col in columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns.csv                ecbdl14-test.arff.gz   ecbdl14-train.csv.gz\r\n",
      "ecbdl14-250k.csv           ecbdl14-test.csv.gz    ecbdl14-train-sample.csv.gz\r\n",
      "ecbdl14.onehot.sample.hdf  ecbdl14-train.arff.gz\r\n"
     ]
    }
   ],
   "source": [
    "%ls /home/jjohn273/git/ECBDL14-Classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ecbdl14 data with shape (3500000, 632)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/jjohn273/git/ECBDL14-Classification/data/ecbdl14-train-sample.csv.gz', header=None, low_memory=False)\n",
    "df.columns = columns\n",
    "print(f'Loaded ecbdl14 data with shape {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there missing values ? False\n"
     ]
    }
   ],
   "source": [
    "print(f'Are there missing values ? {df.isna().any().any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoding categorical variables\n"
     ]
    }
   ],
   "source": [
    "print('One hot encoding categorical variables')\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making train/test split\n",
      "Train shape (2800000, 806) Test shape (700000, 806)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# In[481]:\n",
    "\n",
    "print('Making train/test split')\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f'Train shape {train.shape}', f'Test shape {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, chi2, SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "train_y, train_x = train.loc[:, ['target']], train.drop(columns=['target'])\n",
    "test_y, test_x = test.loc[:, ['target']], test.drop(columns=['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning feature selection\n"
     ]
    }
   ],
   "source": [
    "print('Beginning feature selection')\n",
    "start = time.time()\n",
    "\n",
    "feature_selector = SelectKBest(chi2, k=200)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  ('normalize', MinMaxScaler()),\n",
    "  ('strip_zero_variance', VarianceThreshold()),\n",
    "  ('feature_selector', feature_selector)])\n",
    "\n",
    "train_x_normalized = pipeline.fit_transform(train_x, train_y)\n",
    "test_x_normalized = pipeline.transform(test_x)\n",
    "\n",
    "columns = train_x.columns[feature_selector.get_support()]\n",
    "\n",
    "train_x_normalized = pd.DataFrame(train_x_normalized, columns=columns, index=train_x.index)\n",
    "test_x_normalized = pd.DataFrame(test_x_normalized, columns=columns, index=test_x.index)\n",
    "\n",
    "train_normalized = pd.concat([train_x_normalized, train_y], axis=1)\n",
    "test_normalized = pd.concat([test_x_normalized, test_y], axis=1)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection completed in 83.05122184753418\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature selection completed in {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
