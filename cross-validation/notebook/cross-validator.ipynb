{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/bin/pip3\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "TypeError: 'module' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!pip install --user absl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-0d388fe8457b>\", line 12, in <module>\n",
      "    EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
      "AttributeError: module 'tensorflow' has no attribute 'keras'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python.eager import context as _context\n",
      "  File \"/home/jjohn273/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\", line 25, in <module>\n",
      "    from absl import logging\n",
      "ModuleNotFoundError: No module named 'absl'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "sys.path.append(os.environ['CMS_ROOT'])\n",
    "from cms_modules.utils import model_summary_to_string, args_to_dict\n",
    "from cms_modules.logging import Logger\n",
    "\n",
    "import tensorflow as tf\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
    "TensorBoard = tf.keras.callbacks.TensorBoard\n",
    "# ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau\n",
    "\n",
    "ecbdl14_root = '/home/jjohn273/git/ECBDL14-Classification/'\n",
    "sys.path.append(ecbdl14_root)\n",
    "from model import create_model\n",
    "from CustomCallbacks import KerasRocAucCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DNN Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "hidden_layers_markup='32+32'\n",
    "config['hidden_layers'] = [32,32]\n",
    "config['learn_rate'] = 0.001\n",
    "config['batch_size'] = 128\n",
    "config['dropout_rate'] = 0.5\n",
    "config['batchnorm'] = True\n",
    "epochs=50\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define I/O Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "data_path = os.path.join(ecbdl14_root, 'data/ecbdl14.onehot.sample.hdf')\n",
    "data_key = 'train'\n",
    "# outputs\n",
    "now = datetime.datetime.today()\n",
    "ts = now.strftime(\"%m%d%y-%H%M%S\")\n",
    "validation_auc_outputs = f'{ts}-validation-auc-results.csv'\n",
    "train_auc_outputs = f'{ts}-train-auc-results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_value = f'layers:{hidden_layers_markup}-learn_rate:{config.get(\"learn_rate\")}'\n",
    "config_value += f'-batch_size:{config.get(\"batch_size\")}-dropout_rate:{config.get(\"dropout_rate\")}-bathcnorm:{config.get(\"batchnorm\")}'\n",
    "\n",
    "if not os.path.isfile(train_auc_outputs):\n",
    "    results_header = 'config,fold,' + ','.join([f'ep_{i}' for i in range(epochs)])\n",
    "    output_files = [train_auc_outputs, validation_auc_outputs]\n",
    "    output_headers = [results_header,results_header]\n",
    "    for file, header in zip(output_files, output_headers):\n",
    "        with open(file, 'w') as fout:\n",
    "            fout.write(header + '\\n')\n",
    "\n",
    "def write_results(file, results):\n",
    "    with open(file, 'a') as fout:\n",
    "        fout.write(results + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir = f'tensorboard/{ts}-{config_value}/'\n",
    "log_file = f'logs/{ts}-{config_value}.txt'\n",
    "logger = Logger(log_file)\n",
    "logger.log_time('Starting grid search job')\n",
    "logger.log_time(f'Outputs being written to {[validation_auc_outputs,train_auc_outputs]}')\n",
    "logger.write_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(data_path, data_key)\n",
    "logger.log_time(f'Loaded data with shape {df.shape}').write_to_file()\n",
    "if debug:\n",
    "    y, x = df[:10000]['target'], df[:10000].drop(columns=['target'])\n",
    "else:\n",
    "    y, x = df['target'], df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Over K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "logger.log_time('Starting cross-validation')\n",
    "logger.log_time(f'Using config: {config_value}')\n",
    "\n",
    "# iterate over cross-validation folds\n",
    "for fold, (train_index, validate_index) in enumerate(stratified_cv.split(x, y)):\n",
    "    logger.log_time(f'Starting fold {fold}').write_to_file()\n",
    "    # prepare input data\n",
    "    x_train, y_train = x.iloc[train_index].values, y.iloc[train_index].values\n",
    "    x_valid, y_valid = x.iloc[validate_index].values, y.iloc[validate_index].values\n",
    "    input_dim = x_train.shape[1]\n",
    "\n",
    "    # setup callbacks for monitoring AUC and early stopping\n",
    "    validation_auc_callback = KerasRocAucCallback(x_valid, y_valid, True, logger)\n",
    "    train_auc_callback = KerasRocAucCallback(x_train, y_train)\n",
    "    early_stopping = EarlyStopping(monitor='val_auc', min_delta=0.01, patience=10, mode='max')\n",
    "    tensorboard = TensorBoard(log_dir=f'{tensorboard_dir}/fold-{fold}', write_graph=False)\n",
    "\n",
    "    callbacks = [validation_auc_callback, train_auc_callback, early_stopping, tensorboard]\n",
    "    \n",
    "    # create model and log it's description on 1st run\n",
    "    dnn = create_model(input_dim, config)\n",
    "    if fold == 0:\n",
    "        logger.log_time(model_summary_to_string(dnn)).write_to_file()\n",
    "\n",
    "    # train model\n",
    "    logger.log_time('Starting training...').write_to_file()\n",
    "    history = dnn.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, verbose=0)\n",
    "    logger.log_time('Trainin complete!').write_to_file()\n",
    "    logger.log_time(f'History: {history}')\n",
    "    \n",
    "    # write results\n",
    "    prefix = f'{config_value},{fold}'\n",
    "    validation_aucs = np.array(history.history['val_auc'], dtype=str)\n",
    "    write_results(validation_auc_outputs, f'{prefix},{\",\".join(validation_aucs)}')\n",
    "    train_aucs = np.array(history.history['train_auc'], dtype=str)\n",
    "    write_results(train_auc_outputs, f'{prefix},{\",\".join(train_aucs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_time('Job complete...').write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
