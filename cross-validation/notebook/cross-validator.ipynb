{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/web_services/galaxy/jupyter_conda/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "sys.path.append(os.environ['CMS_ROOT'])\n",
    "from cms_modules.utils import model_summary_to_string, args_to_dict\n",
    "from cms_modules.logging import Logger\n",
    "\n",
    "import tensorflow as tf\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
    "TensorBoard = tf.keras.callbacks.TensorBoard\n",
    "\n",
    "ecbdl14_root = '/home/jjohn273/git/ECBDL14-Classification/'\n",
    "sys.path.append(ecbdl14_root)\n",
    "from model import create_model\n",
    "from CustomCallbacks import KerasRocAucCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DNN Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "hidden_layers_markup='32+32'\n",
    "config['hidden_layers'] = [32,32]\n",
    "config['learn_rate'] = 0.001\n",
    "config['batch_size'] = 128\n",
    "config['dropout_rate'] = 0.5\n",
    "config['batchnorm'] = True\n",
    "epochs=50\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define I/O Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "data_path = os.path.join(ecbdl14_root, 'data/ecbdl14.onehot.sample.hdf')\n",
    "data_key = 'train'\n",
    "# outputs\n",
    "now = datetime.datetime.today()\n",
    "ts = now.strftime(\"%m%d%y-%H%M%S\")\n",
    "validation_auc_outputs = f'{ts}-validation-auc-results.csv'\n",
    "train_auc_outputs = f'{ts}-train-auc-results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_value = f'layers:{hidden_layers_markup}-learn_rate:{config.get(\"learn_rate\")}'\n",
    "config_value += f'-batch_size:{config.get(\"batch_size\")}-dropout_rate:{config.get(\"dropout_rate\")}-bathcnorm:{config.get(\"batchnorm\")}'\n",
    "\n",
    "if not os.path.isfile(train_auc_outputs):\n",
    "    results_header = 'config,fold,' + ','.join([f'ep_{i}' for i in range(epochs) if i%callback_freq == 0])\n",
    "    output_files = [train_auc_outputs, validation_auc_outputs]\n",
    "    output_headers = [results_header,results_header]\n",
    "    for file, header in zip(output_files, output_headers):\n",
    "        with open(file, 'w') as fout:\n",
    "            fout.write(header + '\\n')\n",
    "\n",
    "def write_results(file, results):\n",
    "    with open(file, 'a') as fout:\n",
    "        fout.write(results + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir = f'tensorboard'\n",
    "log_file = f'logs/{ts}-{config_value}.txt'\n",
    "logger = Logger(log_file)\n",
    "logger.log_time('Starting grid search job')\n",
    "logger.log_time(f'Outputs being written to {[validation_auc_outputs,train_auc_outputs]}')\n",
    "logger.write_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(data_path, data_key)\n",
    "logger.log_time(f'Loaded data with shape {df.shape}').write_to_file()\n",
    "if debug:\n",
    "    y, x = df[:10000]['target'], df[:10000].drop(columns=['target'])\n",
    "else:\n",
    "    y, x = df['target'], df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Over K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stratified_cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "logger.log_time('Starting cross-validation')\n",
    "logger.log_time(f'Using config: {config_value}')\n",
    "\n",
    "# iterate over cross-validation folds\n",
    "for fold, (train_index, validate_index) in enumerate(stratified_cv.split(x, y)):\n",
    "    logger.log_time(f'Starting fold {fold}').write_to_file()\n",
    "    # prepare input data\n",
    "    x_train, y_train = x.iloc[train_index].values, y.iloc[train_index].values\n",
    "    x_valid, y_valid = x.iloc[validate_index].values, y.iloc[validate_index].values\n",
    "    input_dim = x_train.shape[1]\n",
    "\n",
    "    # setup callbacks for monitoring AUC and early stopping\n",
    "    validation_auc_callback = KerasRocAucCallback(x_valid, y_valid, True, logger)\n",
    "    train_auc_callback = KerasRocAucCallback(x_train, y_train)\n",
    "    early_stopping = EarlyStopping(monitor='val_auc', min_delta=0.01, patience=10, mode='max')\n",
    "    tensorboard = TensorBoard(log_dir=f'{tensorboard_dir}/{config_value}/fold-{fold}', write_graph=False)\n",
    "\n",
    "    callbacks = [validation_auc_callback, train_auc_callback, early_stopping, tensorboard]\n",
    "    \n",
    "    # create model and log it's description on 1st run\n",
    "    dnn = create_model(input_dim, config)\n",
    "    if fold == 0:\n",
    "        logger.log_time(model_summary_to_string(dnn)).write_to_file()\n",
    "\n",
    "    # train model\n",
    "    logger.log_time('Starting training...').write_to_file()\n",
    "    history = dnn.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, verbose=0)\n",
    "    logger.log_time('Trainin complete!').write_to_file()\n",
    "    logger.log_time(f'History: {history}')\n",
    "    \n",
    "    # write results\n",
    "    prefix = f'{config_value},{fold}'\n",
    "    validation_aucs = np.array(history.history['val_auc'], dtype=str)\n",
    "    write_results(validation_auc_outputs, f'{prefix},{\",\".join(validation_aucs)}')\n",
    "    train_aucs = np.array(history.history['train_auc'], dtype=str)\n",
    "    write_results(train_auc_outputs, f'{prefix},{\",\".join(train_aucs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - Tensorflow",
   "language": "python",
   "name": "python3-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
